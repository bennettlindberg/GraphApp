#
# Lambda function that handles the creation of new graphs
# by placing graph data files in the S3 bucket and creating
# graph entries in the RDS database.
#
# Authors:
#   Bennett Lindberg
#
#   Prof. Joe Hummel (initial template, from project03)
#   Northwestern University
#   CS 310
#

import json
import boto3
import os
import uuid
import base64
import datatier

from configparser import ConfigParser


def lambda_handler(event, context):
    try:
        print("**STARTING**")
        print("**lambda: final_upload_graph**")

        #
        # set up AWS based on config file
        #
        config_file = "graphapp-config.ini"
        os.environ["AWS_SHARED_CREDENTIALS_FILE"] = config_file

        configur = ConfigParser()
        configur.read(config_file)

        #
        # configure for S3 access
        #
        s3_profile = "s3readwrite"
        boto3.setup_default_session(profile_name=s3_profile)

        bucketname = configur.get("s3", "bucket_name")

        s3 = boto3.resource("s3")
        bucket = s3.Bucket(bucketname)

        #
        # configure for RDS access
        #
        rds_endpoint = configur.get("rds", "endpoint")
        rds_portnum = int(configur.get("rds", "port_number"))
        rds_username = configur.get("rds", "user_name")
        rds_pwd = configur.get("rds", "user_pwd")
        rds_dbname = configur.get("rds", "db_name")

        #
        # get graph file data from request
        #
        print("**Accessing request body**")

        if "body" not in event:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {"message": "no body data provided in the request", "graphid": -1}
                ),
            }

        body = json.loads(event["body"])

        if "data" not in body:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {"message": "no data key provided in the body", "graphid": -1}
                ),
            }

        datastr = body["data"]

        #
        # convert file byte format
        #
        base64_bytes = datastr.encode()
        bytes = base64.b64decode(base64_bytes)

        #
        # check graph for validity
        #
        graph_data = json.loads(bytes.decode())

        validation_result = validate_graph(graph_data)
        if validation_result != None:
            return validation_result

        #
        # copy file to tmp folder
        #
        print("**Writing local data file**")

        local_filename = "/tmp/local_graph_data_file.json"
        f = open(local_filename, "wb")
        f.write(bytes)
        f.close()

        #
        # generate unique filename in preparation for the S3 upload
        #
        print("**Uploading local file to S3**")

        bucketkey = "graphapp/" + "graph_data_file_" + str(uuid.uuid4()) + ".json"

        print("Using S3 bucketkey:", bucketkey)

        #
        # upload file to S3
        #
        bucket.upload_file(
            local_filename,
            bucketkey,
            ExtraArgs={"ACL": "public-read", "ContentType": "application/json"},
        )

        #
        # open connection to database
        #
        print("**Opening DB connection**")

        dbConn = datatier.get_dbConn(
            rds_endpoint, rds_portnum, rds_username, rds_pwd, rds_dbname
        )

        #
        # create new graph row in database
        #
        print("**Adding graph row to database**")

        sql = """
        INSERT INTO graphs(datafilekey, visualfilekey)
                    VALUES(%s, %s);
        """

        datatier.perform_action(dbConn, sql, [bucketkey, None])

        #
        # grab the graphid that was auto-generated by mysql
        #
        sql = "SELECT LAST_INSERT_ID();"

        row = datatier.retrieve_one_row(dbConn, sql)

        graphid = row[0]

        print("Created row with graphid:", graphid)

        #
        # success: 200 OK
        #
        print("**DONE, returning success**")

        return {
            "statusCode": 200,
            "body": json.dumps({"message": "success", "graphid": graphid}),
        }

    #
    # error: 500 INTERNAL SERVER ERROR
    #
    except Exception as err:
        print("**ERROR**")
        print(str(err))

        return {
            "statusCode": 500,
            "body": json.dumps({"message": str(err), "graphid": -1}),
        }


def validate_graph(graph_data):
    if "vertices" not in graph_data:
        return {
            "statusCode": 400,
            "body": json.dumps(
                {"message": "no vertices key graph data file", "graphid": -1}
            ),
        }

    if "edges" not in graph_data:
        return {
            "statusCode": 400,
            "body": json.dumps(
                {"message": "no edges key graph data file", "graphid": -1}
            ),
        }

    if len(graph_data["vertices"]) < 1:
        return {
            "statusCode": 400,
            "body": json.dumps(
                {"message": "graph must contain at least one vertex", "graphid": -1}
            ),
        }

    for index, vertex in enumerate(graph_data["vertices"]):
        if not (isinstance(vertex, int) and not isinstance(vertex, bool)):  # int check
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"vertex identifier {vertex} is not an integer",
                        "graphid": -1,
                    }
                ),
            }
        elif vertex in graph_data["vertices"][(index + 1) :]:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"vertex identifier {vertex} is not unique",
                        "graphid": -1,
                    }
                ),
            }

    for index, edge in enumerate(graph_data["edges"]):
        if len(edge) != 3:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"edge {edge} is not an array of three items",
                        "graphid": -1,
                    }
                ),
            }
        elif edge[0] not in graph_data["vertices"]:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"edge endpoint {edge[0]} is not a vertex identifier",
                        "graphid": -1,
                    }
                ),
            }
        elif edge[1] not in graph_data["vertices"]:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"edge endpoint {edge[1]} is not a vertex identifier",
                        "graphid": -1,
                    }
                ),
            }
        elif edge[0] == edge[1]:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"vertices cannot have self loops",
                        "graphid": -1,
                    }
                ),
            }
        elif edge[2] <= 0:
            return {
                "statusCode": 400,
                "body": json.dumps(
                    {
                        "message": f"edge weight {edge[2]} is not positive",
                        "graphid": -1,
                    }
                ),
            }
        else:
            for other_edge in graph_data["edges"][0:index]:
                if (other_edge[0] == edge[0] and other_edge[1] == edge[1]) or (
                    other_edge[1] == edge[0] and other_edge[0] == edge[1]
                ):
                    return {
                        "statusCode": 400,
                        "body": json.dumps(
                            {
                                "message": f"duplicate edge ({edge[0]}, {edge[1]}) exists",
                                "graphid": -1,
                            }
                        ),
                    }

    # success case
    return None
